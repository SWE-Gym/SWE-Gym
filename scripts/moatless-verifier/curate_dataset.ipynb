{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from collections import defaultdict\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_prefix = \"release-32b-it1-trainlite-temp_1.0-fp8_\"\n",
    "raw_data_files = glob.glob(raw_data_prefix + \"*\")\n",
    "raw_datasets = [json.load(open(f)) for f in raw_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset format D[instance_id][True/False] = [msg1, msg2, ...]\n",
    "D = defaultdict(lambda: defaultdict(lambda: []))\n",
    "for raw_dataset in raw_datasets:\n",
    "    for instance_id, messages in raw_dataset.items():\n",
    "        is_success = \"True\" in messages[2]['content']\n",
    "        D[instance_id][is_success].append(messages)\n",
    "\n",
    "# Cap each instance at 2 messages for both positive and negative\n",
    "from random import shuffle, seed\n",
    "seed(42)\n",
    "\n",
    "CAP_PER_INSTANCE = 2\n",
    "success_msgs = []\n",
    "for instance_id in D.keys():\n",
    "    if D[instance_id][True]:  # If there are positive messages\n",
    "        instance_msgs = D[instance_id][True]\n",
    "        shuffle(instance_msgs)\n",
    "        success_msgs.extend(instance_msgs[:CAP_PER_INSTANCE])  # Cap at 2 per instance\n",
    "\n",
    "fail_msgs = []\n",
    "for instance_id in D.keys():\n",
    "    if D[instance_id][False]:  # If there are negative messages\n",
    "        instance_msgs = D[instance_id][False]\n",
    "        shuffle(instance_msgs)\n",
    "        fail_msgs.extend(instance_msgs[:CAP_PER_INSTANCE])  # Cap at 2 per instance\n",
    "\n",
    "# Randomly subsample negative messages to match positive count\n",
    "shuffle(fail_msgs)\n",
    "complete_msgs = success_msgs + fail_msgs[:len(success_msgs)]  # 1:1 ratio\n",
    "shuffle(complete_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(success_msgs), len(fail_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(complete_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_dataset = []\n",
    "for msg in complete_msgs:\n",
    "    openai_dataset.append({\n",
    "        \"messages\": msg,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-32B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg_len(msg):\n",
    "    return len(tokenizer.apply_chat_template(msg['messages'], tokenize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_msg_pair = [(msg_len(msg), msg) for msg in openai_dataset]\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lens = [l for l, _ in lens_msg_pair]\n",
    "# Sort lengths for CDF\n",
    "sorted_lens = np.sort(lens)\n",
    "# Calculate cumulative probabilities\n",
    "cumulative_probs = np.arange(1, len(sorted_lens) + 1) / len(sorted_lens)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_lens, cumulative_probs)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Message Length (tokens)')\n",
    "plt.ylabel('Cumulative Proportion')\n",
    "plt.title('CDF of Message Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pairs(lens_msg_pair, max_len=10240):\n",
    "    return [msg for l, msg in lens_msg_pair if l <= max_len]\n",
    "filtered_pairs = filter_pairs(lens_msg_pair, max_len=10240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_pairs)\n",
    "with open(\"release_orm_32b-cap2.openai.jsonl\", \"w\") as f:\n",
    "    for msg in filtered_pairs:\n",
    "        f.write(json.dumps(msg) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moatless",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
